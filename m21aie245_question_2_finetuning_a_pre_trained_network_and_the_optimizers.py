# -*- coding: utf-8 -*-
"""M21AIE245_Question_2_Finetuning_a_pre_trained_network_and_the_optimizers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s73eHNvldc8W97CWCGmJnYsf_ZKTOEBv
"""

import torch
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt



import torchvision.models as models
model = models.resnet101(pretrained=True)



from torchvision import datasets, transforms
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])
# Replace 'FashionMNIST' with 'STL10' or 'SVHN' as needed
dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)

last_digit = 5
if last_digit % 3 == 0:
    dataset = torchvision.datasets.STL10(root='./data', split='train', transform=transform, download=True)
elif last_digit % 3 == 1:
    dataset = torchvision.datasets.SVHN(root='./data', split='train', transform=transform, download=True)
else:
    dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)

dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
model = torchvision.models.resnet101(pretrained=True)



num_classes = 10  # Update this to match the number of classes in your dataset
model.fc = nn.Linear(model.fc.in_features, num_classes)

import torch
import torch.nn as nn
from torch.optim import Adam, Adagrad, Adadelta, RMSprop

# Define the optimizers
optimizers = {
    'Adam': Adam(model.parameters(), lr=0.001),
    'Adagrad': Adagrad(model.parameters(), lr=0.001),
    'Adadelta': Adadelta(model.parameters(), lr=1.0),
    'RMSprop': RMSprop(model.parameters(), lr=0.01)
}

trainset = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=transform)
testset = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=transform)

train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)
test_loader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)

optimizer_choice = 'Adam'
optimizer = optimizers[optimizer_choice]

criterion = nn.CrossEntropyLoss()

num_epochs =5
for name, optimizer in optimizers.items():
    print(f'Training with {name} optimizer')

    for epoch in range(num_epochs):
        for i, (images, labels) in enumerate(train_loader):
            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Backward pass and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (i+1) % 100 == 0:
                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item()}')

def top_k_accuracy(input, target, k):
    with torch.no_grad():
        _, pred = input.topk(k, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))
        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)
        return correct_k.mul_(100.0 / input.size(0))

model.eval()  # Set the model to evaluation mode
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        top5_acc = top_k_accuracy(outputs, labels, 5)
    print(f'Top-1 Accuracy of the model on the test images: {100 * correct / total}%')
    print(f'Top-5 Accuracy of the model on the test images: {top5_acc.item()}%')

from torch.utils.tensorboard import SummaryWriter
num_epochs =5
writer = SummaryWriter()

for epoch in range(5):
    running_loss = 0.0
    running_corrects = 0
    for i, (images, labels) in enumerate(train_loader):
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward pass and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        _, preds = torch.max(outputs, 1)
        running_corrects += torch.sum(preds == labels.data)

    epoch_loss = running_loss / len(train_loader.dataset)
    epoch_acc = running_corrects.double() / len(train_loader.dataset)

    writer.add_scalar('training loss', epoch_loss, epoch)
    writer.add_scalar('training accuracy', epoch_acc, epoch)

writer.close()

from torch.utils.tensorboard import SummaryWriter

# Commented out IPython magic to ensure Python compatibility.
%load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir runs

